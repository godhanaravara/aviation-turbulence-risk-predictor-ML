{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3236d2cd-1bd2-4640-8ff0-4678434f7de5",
   "metadata": {},
   "source": [
    "# ▸ Model Training & Performance Evaluation\n",
    "\n",
    "\n",
    "This notebook covers model training for turbulence-risk classification using stratified 10-fold cross-validation. The focus is on building models that are both accurate and robust to class imbalance, and comparing multiple ML algorithms to identify the most effective one.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817585af-3c34-49f7-b942-a6db7be5209f",
   "metadata": {},
   "source": [
    "## 1. Why 10-Fold Stratified Cross-Validation?\n",
    "\n",
    "In datasets with class imbalance (like this dataset in this project where severe turbulence is rare), stratified CV helps ensure that each fold maintains the original class distribution. This avoids overfitting to the majority class and gives a more realistic view of model performance.\n",
    "\n",
    "Used a 10 folds to strike a balance between training time and robust performance metrics.\n",
    "\n",
    "Each model was evaluated using:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "\n",
    "All results reflect the average across the 10 folds.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fd19d2-a9fd-4e2a-8ed1-972c5ad3f787",
   "metadata": {},
   "source": [
    "## 2. Training the Models\n",
    "\n",
    "The following models were trained and evaluated:\n",
    "\n",
    "- XGBoost (main model)\n",
    "- Random Forest\n",
    "- LightGBM\n",
    "- CatBoost\n",
    "- TabNet (deep learning)\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Support Vector Machine (SVM)\n",
    "\n",
    "All models followed the same pipeline:\n",
    "\n",
    "- Train using stratified CV\n",
    "- Predict probabilities\n",
    "- Convert to binary predictions using an optimal threshold (0.45 - chosen by best F1)\n",
    "- Save the model and optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec41c9-7e88-4660-9729-3e5412cbc6cd",
   "metadata": {},
   "source": [
    "Here’s how it looked in code:\n",
    "\n",
    "```python\n",
    "# For each model:\n",
    "model, best_thresh = train_model_cv(X, y, model_type=model_name, threshold=0.45)\n",
    "trained_models[model_name] = model\n",
    "optimal_thresholds[model_name] = best_thrsh\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6058c376-7e07-43ce-bd64-d69953a912f8",
   "metadata": {},
   "source": [
    "## 3. Cross-Validation Performance\n",
    "Models across Accuracy, Precision, Recall, and F1-score were compared to understand trade-offs.\n",
    "\n",
    "**Performance Comparison Across Models**\n",
    "\n",
    "![comparison_output_report](images/comparison_output_report.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9ac89-b118-41e0-8165-e386b4ade8bc",
   "metadata": {},
   "source": [
    "- **XGBoost, Random Forest, LightGBM, and CatBoost** performed consistently well across all metrics.\n",
    "- **TabNet** also gave strong results, especially in Recall, highlighting its strength on rare events.\n",
    "- **Naive Bayes, KNN, and SVM** underperformed, especially in Precision and F1 - not ideal for imbalanced classification.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f0710-3dd1-4b8c-b7dc-cce94b34fa62",
   "metadata": {},
   "source": [
    "## 4. ROC-AUC Analysis\n",
    "The ROC curve gives insight into the true positive vs false positive tradeoff at all thresholds. AUC (Area Under Curve) was used as a key comparison metric.\n",
    "\n",
    "![roc_auc_curve](images/roc_auc_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af52e4b-ea32-4203-b524-11e8cb0bdbee",
   "metadata": {},
   "source": [
    "- **XGBoost, CatBoost, LightGBM, and Random Forest** all reached an AUC of ~0.97.\n",
    "- **TabNet** also followed closely with an AUC of 0.96.\n",
    "- **SVM** lagged behind significantly, making it the weakest fit for this task.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc41ca-e62e-4d57-8565-9f8ab674985e",
   "metadata": {},
   "source": [
    "## 5. Why XGBoost?\n",
    "XGBoost was chosen as the primary model based on:\n",
    "\n",
    "- Consistent top-tier performance in all metrics\n",
    "- Flexibility in tuning for class imbalance (via scale_pos_weight)\n",
    "- Robustness to overfitting due to inbuilt regularization\n",
    "- Fast training even on large feature sets\n",
    "\n",
    "It gave the best balance of Recall and F1, which is critical for detecting rare but severe turbulence events without triggering too many false alarms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf5da4-bb3f-4eed-b9a0-ccb66dea16e5",
   "metadata": {},
   "source": [
    "## ▸ In conclusion\n",
    "The final model ensemble highlights how different algorithms handle turbulence prediction differently. By training and validating using the same pipeline, a fair comparison was ensured.\n",
    "- Business impact: Choosing the right model directly affects flight safety insights. A model with high Recall ensures fewer missed warnings, while strong Precision avoids unnecessary alerts.\n",
    "- Technical reliability: Robust cross-validation ensures that our results generalize well and aren't artifacts of overfitting or sampling errors.\n",
    "\n",
    "The top models from this step are carried forward into downstream testing and risk map visualizations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projectML)",
   "language": "python",
   "name": "projectml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
