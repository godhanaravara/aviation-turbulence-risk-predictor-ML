{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa221c9-60f5-4c08-b6dc-4456a557b97a",
   "metadata": {},
   "source": [
    "# ▸ Extended Model Evaluation and Case Insights\n",
    "\n",
    "\n",
    "Beyond raw performance metrics, I explored how different preprocessing choices, model types, and real-world samples influenced turbulence prediction outcomes. These analyses helped validate the model's consistency and offered ideas for operational relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d088742-afdb-4ad3-8993-71605befe81e",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Preprocessing Strategy: Why It Matters\n",
    "\n",
    "To understand the impact of different balancing and transformation techniques, I evaluated six preprocessing combinations using XGBoost as the base classifier.\n",
    "\n",
    "![ablation_study_table](images/ablation_study_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd39f11-dfa7-4d6e-97b9-fd2f9c79f4dd",
   "metadata": {},
   "source": [
    "As shown above, the raw dataset (without any balancing) achieved high overall accuracy (96.6%) but failed to detect many of the SEV–EXTRM turbulence cases. On the other hand, approaches that included SMOTE and downsampling improved recall and F1-score substantially, especially for the rare, high-risk class.\n",
    "\n",
    "The Full Pipeline, which combined SMOTE, anomaly-guided downsampling, PCA-based dimensionality reduction, and K-Means clustering for risk labeling, delivered the best overall balance:\n",
    "\n",
    "- Recall: 91% for SEV–EXTRM\n",
    "- F1-score: 0.88\n",
    "- False negatives: **reduced more effectively than any other pipeline**, which is critical for a risk-sensitive domain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f9c53-b1e0-4414-8262-04b7b59506a6",
   "metadata": {},
   "source": [
    "While SMOTE + Downsampling came very close in terms of recall and F1, the Full Pipeline had several subtle advantages:\n",
    "\n",
    "- PCA helped **reduce noise** and **feature redundancy, improving generalization**.\n",
    "- K-Means labeling enabled **better structure-aware learning**, especially when fed into models like XGBoost that benefit from informative feature clusters.\n",
    "- From a modeling perspective, the combined pipeline allowed for **more interpretable** and **spatially consistent results**, making downstream evaluation and validation more robust.\n",
    "\n",
    "So while the gains may seem incremental numerically, the Full Pipeline offered better reliability when scaled across validation folds and test scenarios, which ultimately made it the more trustworthy setup for operational use.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792c58a-73c7-4524-87b8-be46775bf386",
   "metadata": {},
   "source": [
    "## 2. Model Behavior Comparison - SVM vs XGBoost\n",
    "\n",
    "Since Mizuno et al. originally used an SVM model, I replicated their approach and contrasted it with my pipeline’s results.\n",
    "\n",
    "**(SVM vs SVM)**\n",
    "![conf_final](images/conf_final.png)\n",
    "My SVM model showed reduced performance on this dataset, especially for correctly identifying severe turbulence. \n",
    "\n",
    "On the other hand:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2cdbb4-1836-4038-8e11-fadef2eea0fb",
   "metadata": {},
   "source": [
    "**(SVM vs XGBoost)**\n",
    "![conf_final_xgboost](images/conf_final_xgboost.png)\n",
    "\n",
    "✮ XGBoost offered stronger generalization. It correctly identified 90.7% of SEV–EXTRM reports while keeping false positives (false alarms) under control which is important in operational aviation scenarios.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc058f7-1af3-4ce9-9e36-21126e4ada36",
   "metadata": {},
   "source": [
    "## 3. Case Study: February 16, 2025\n",
    "\n",
    "To test model robustness on unseen data, I selected a real high-risk day from the 2025 test set. The map below shows how well the XGBoost model captured true positive zones:\n",
    "\n",
    "![feb_16th_map_view](images/feb_16th_map_view.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c9472-9233-4054-9fa0-e71b2b75ef02",
   "metadata": {},
   "source": [
    "I focused on two locations where the model accurately flagged SEV–EXTRM cases: Ohio and North Carolina. Here's how their conditions differed from the 2024 baseline:\n",
    "\n",
    "![case_study_analysis](images/case_study_analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21558504-00ee-4ee9-b9da-95168f0c458d",
   "metadata": {},
   "source": [
    "- Wind speeds, vertical velocity, and temperature all deviated significantly. This supports the model’s reliance on meaningful physical indicators.\n",
    "\n",
    "ⓘ These explanations aren’t meant as expert meteorological validation but illustrate how the model learned useful, generalizable patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f96ad-1dcc-461f-8064-b51d7c4faf88",
   "metadata": {},
   "source": [
    "---\n",
    "## ▸ Key Insights and Model Reflections\n",
    "\n",
    "This pipeline was built for more than just scoring high on cross-validation. It was designed to:\n",
    "\n",
    "- Prioritize recall and F1-score for severe events\n",
    "- Reduce false negatives, which are critical in safety contexts\n",
    "- Offer a way to visually interpret predictions using K-Means clustering\n",
    "- Provide traceability and feature deviation analysis on high-risk days\n",
    "\n",
    "While XGBoost performed the best overall, the deeper evaluations gave confidence that the predictions weren’t just fitting noise but **they matched real-world patterns** in **wind speed, vertical motion, and cloud features**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projectML)",
   "language": "python",
   "name": "projectml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
